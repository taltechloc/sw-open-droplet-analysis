{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3fe1a0-2e14-4332-baea-e2455db5a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525f26e-f299-4004-a2bc-0ecd75c746d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training set and val set\n",
      "Train set size: (917,) (917, 10)\n",
      "Validation set size: (101,) (101, 10)\n",
      "Train and validation datasets ready!\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " enhanced_transformer_block   (None, 256)              789504    \n",
      " (EnhancedTransformerBlock)                                      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,052,554\n",
      "Trainable params: 823,690\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer EnhancedTransformerBlock has arguments ['embed_dim', 'num_heads', 'ff_dim', 'dropout_rate']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 2.0575 - categorical_accuracy: 0.1138 - spearman_correlation_tf: 0.1522 - pearson_correlation_tf: 0.1116\n",
      "Epoch 1: val_spearman_correlation_tf improved from -inf to 0.15644, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 5s 124ms/step - loss: 2.0575 - categorical_accuracy: 0.1138 - spearman_correlation_tf: 0.1522 - pearson_correlation_tf: 0.1116 - val_loss: 1.9953 - val_categorical_accuracy: 0.1146 - val_spearman_correlation_tf: 0.1564 - val_pearson_correlation_tf: 0.1211 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.9126 - categorical_accuracy: 0.1458 - spearman_correlation_tf: 0.2348 - pearson_correlation_tf: 0.2327\n",
      "Epoch 2: val_spearman_correlation_tf improved from 0.15644 to 0.16894, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 114ms/step - loss: 1.9126 - categorical_accuracy: 0.1458 - spearman_correlation_tf: 0.2348 - pearson_correlation_tf: 0.2327 - val_loss: 1.8646 - val_categorical_accuracy: 0.1042 - val_spearman_correlation_tf: 0.1689 - val_pearson_correlation_tf: 0.1903 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.7974 - categorical_accuracy: 0.1593 - spearman_correlation_tf: 0.2794 - pearson_correlation_tf: 0.2935\n",
      "Epoch 3: val_spearman_correlation_tf improved from 0.16894 to 0.27639, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 1.7974 - categorical_accuracy: 0.1593 - spearman_correlation_tf: 0.2794 - pearson_correlation_tf: 0.2935 - val_loss: 1.7596 - val_categorical_accuracy: 0.0938 - val_spearman_correlation_tf: 0.2764 - val_pearson_correlation_tf: 0.2491 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6986 - categorical_accuracy: 0.1831 - spearman_correlation_tf: 0.3383 - pearson_correlation_tf: 0.3235\n",
      "Epoch 4: val_spearman_correlation_tf improved from 0.27639 to 0.36856, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 130ms/step - loss: 1.6986 - categorical_accuracy: 0.1831 - spearman_correlation_tf: 0.3383 - pearson_correlation_tf: 0.3235 - val_loss: 1.6646 - val_categorical_accuracy: 0.1354 - val_spearman_correlation_tf: 0.3686 - val_pearson_correlation_tf: 0.2903 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.6067 - categorical_accuracy: 0.1864 - spearman_correlation_tf: 0.3801 - pearson_correlation_tf: 0.3460\n",
      "Epoch 5: val_spearman_correlation_tf improved from 0.36856 to 0.37121, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 136ms/step - loss: 1.6067 - categorical_accuracy: 0.1864 - spearman_correlation_tf: 0.3801 - pearson_correlation_tf: 0.3460 - val_loss: 1.5752 - val_categorical_accuracy: 0.1458 - val_spearman_correlation_tf: 0.3712 - val_pearson_correlation_tf: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.5227 - categorical_accuracy: 0.1831 - spearman_correlation_tf: 0.4035 - pearson_correlation_tf: 0.3572\n",
      "Epoch 6: val_spearman_correlation_tf improved from 0.37121 to 0.39343, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 139ms/step - loss: 1.5227 - categorical_accuracy: 0.1831 - spearman_correlation_tf: 0.4035 - pearson_correlation_tf: 0.3572 - val_loss: 1.4912 - val_categorical_accuracy: 0.1562 - val_spearman_correlation_tf: 0.3934 - val_pearson_correlation_tf: 0.3186 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.4388 - categorical_accuracy: 0.2136 - spearman_correlation_tf: 0.4437 - pearson_correlation_tf: 0.3851\n",
      "Epoch 7: val_spearman_correlation_tf improved from 0.39343 to 0.45896, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 152ms/step - loss: 1.4388 - categorical_accuracy: 0.2136 - spearman_correlation_tf: 0.4437 - pearson_correlation_tf: 0.3851 - val_loss: 1.4118 - val_categorical_accuracy: 0.1979 - val_spearman_correlation_tf: 0.4590 - val_pearson_correlation_tf: 0.3365 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.3640 - categorical_accuracy: 0.2215 - spearman_correlation_tf: 0.4695 - pearson_correlation_tf: 0.3832\n",
      "Epoch 8: val_spearman_correlation_tf improved from 0.45896 to 0.46124, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 138ms/step - loss: 1.3640 - categorical_accuracy: 0.2215 - spearman_correlation_tf: 0.4695 - pearson_correlation_tf: 0.3832 - val_loss: 1.3431 - val_categorical_accuracy: 0.2083 - val_spearman_correlation_tf: 0.4612 - val_pearson_correlation_tf: 0.3227 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2884 - categorical_accuracy: 0.2395 - spearman_correlation_tf: 0.4902 - pearson_correlation_tf: 0.3975\n",
      "Epoch 9: val_spearman_correlation_tf improved from 0.46124 to 0.47891, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 135ms/step - loss: 1.2884 - categorical_accuracy: 0.2395 - spearman_correlation_tf: 0.4902 - pearson_correlation_tf: 0.3975 - val_loss: 1.2673 - val_categorical_accuracy: 0.2188 - val_spearman_correlation_tf: 0.4789 - val_pearson_correlation_tf: 0.3477 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.2248 - categorical_accuracy: 0.2045 - spearman_correlation_tf: 0.4855 - pearson_correlation_tf: 0.3838\n",
      "Epoch 10: val_spearman_correlation_tf improved from 0.47891 to 0.48081, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 1.2248 - categorical_accuracy: 0.2045 - spearman_correlation_tf: 0.4855 - pearson_correlation_tf: 0.3838 - val_loss: 1.1994 - val_categorical_accuracy: 0.2188 - val_spearman_correlation_tf: 0.4808 - val_pearson_correlation_tf: 0.3508 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1551 - categorical_accuracy: 0.2203 - spearman_correlation_tf: 0.5184 - pearson_correlation_tf: 0.4238\n",
      "Epoch 11: val_spearman_correlation_tf improved from 0.48081 to 0.54482, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 122ms/step - loss: 1.1551 - categorical_accuracy: 0.2203 - spearman_correlation_tf: 0.5184 - pearson_correlation_tf: 0.4238 - val_loss: 1.1474 - val_categorical_accuracy: 0.1979 - val_spearman_correlation_tf: 0.5448 - val_pearson_correlation_tf: 0.3181 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0899 - categorical_accuracy: 0.2475 - spearman_correlation_tf: 0.5579 - pearson_correlation_tf: 0.4398\n",
      "Epoch 12: val_spearman_correlation_tf improved from 0.54482 to 0.58510, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 1.0899 - categorical_accuracy: 0.2475 - spearman_correlation_tf: 0.5579 - pearson_correlation_tf: 0.4398 - val_loss: 1.0813 - val_categorical_accuracy: 0.2292 - val_spearman_correlation_tf: 0.5851 - val_pearson_correlation_tf: 0.3570 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.0326 - categorical_accuracy: 0.2407 - spearman_correlation_tf: 0.5912 - pearson_correlation_tf: 0.4554\n",
      "Epoch 13: val_spearman_correlation_tf improved from 0.58510 to 0.62210, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 133ms/step - loss: 1.0326 - categorical_accuracy: 0.2407 - spearman_correlation_tf: 0.5912 - pearson_correlation_tf: 0.4554 - val_loss: 1.0121 - val_categorical_accuracy: 0.2292 - val_spearman_correlation_tf: 0.6221 - val_pearson_correlation_tf: 0.4435 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9702 - categorical_accuracy: 0.2712 - spearman_correlation_tf: 0.5912 - pearson_correlation_tf: 0.4933\n",
      "Epoch 14: val_spearman_correlation_tf improved from 0.62210 to 0.62323, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 137ms/step - loss: 0.9702 - categorical_accuracy: 0.2712 - spearman_correlation_tf: 0.5912 - pearson_correlation_tf: 0.4933 - val_loss: 0.9535 - val_categorical_accuracy: 0.2917 - val_spearman_correlation_tf: 0.6232 - val_pearson_correlation_tf: 0.5033 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9191 - categorical_accuracy: 0.2712 - spearman_correlation_tf: 0.6068 - pearson_correlation_tf: 0.4977\n",
      "Epoch 15: val_spearman_correlation_tf improved from 0.62323 to 0.64015, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 126ms/step - loss: 0.9191 - categorical_accuracy: 0.2712 - spearman_correlation_tf: 0.6068 - pearson_correlation_tf: 0.4977 - val_loss: 0.8983 - val_categorical_accuracy: 0.2708 - val_spearman_correlation_tf: 0.6402 - val_pearson_correlation_tf: 0.5177 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8654 - categorical_accuracy: 0.2610 - spearman_correlation_tf: 0.6447 - pearson_correlation_tf: 0.5292\n",
      "Epoch 16: val_spearman_correlation_tf improved from 0.64015 to 0.67538, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 0.8654 - categorical_accuracy: 0.2610 - spearman_correlation_tf: 0.6447 - pearson_correlation_tf: 0.5292 - val_loss: 0.8415 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.6754 - val_pearson_correlation_tf: 0.5755 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.8184 - categorical_accuracy: 0.2746 - spearman_correlation_tf: 0.6524 - pearson_correlation_tf: 0.5499\n",
      "Epoch 17: val_spearman_correlation_tf did not improve from 0.67538\n",
      "28/28 [==============================] - 4s 126ms/step - loss: 0.8184 - categorical_accuracy: 0.2746 - spearman_correlation_tf: 0.6524 - pearson_correlation_tf: 0.5499 - val_loss: 0.8057 - val_categorical_accuracy: 0.2708 - val_spearman_correlation_tf: 0.6628 - val_pearson_correlation_tf: 0.5653 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7743 - categorical_accuracy: 0.2633 - spearman_correlation_tf: 0.6575 - pearson_correlation_tf: 0.5694\n",
      "Epoch 18: val_spearman_correlation_tf improved from 0.67538 to 0.69419, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 125ms/step - loss: 0.7743 - categorical_accuracy: 0.2633 - spearman_correlation_tf: 0.6575 - pearson_correlation_tf: 0.5694 - val_loss: 0.7535 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.6942 - val_pearson_correlation_tf: 0.6011 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.7302 - categorical_accuracy: 0.2893 - spearman_correlation_tf: 0.6696 - pearson_correlation_tf: 0.5876\n",
      "Epoch 19: val_spearman_correlation_tf improved from 0.69419 to 0.70467, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 124ms/step - loss: 0.7302 - categorical_accuracy: 0.2893 - spearman_correlation_tf: 0.6696 - pearson_correlation_tf: 0.5876 - val_loss: 0.7115 - val_categorical_accuracy: 0.3229 - val_spearman_correlation_tf: 0.7047 - val_pearson_correlation_tf: 0.6218 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6878 - categorical_accuracy: 0.2802 - spearman_correlation_tf: 0.6816 - pearson_correlation_tf: 0.6139\n",
      "Epoch 20: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 120ms/step - loss: 0.6878 - categorical_accuracy: 0.2802 - spearman_correlation_tf: 0.6816 - pearson_correlation_tf: 0.6139 - val_loss: 0.6796 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.6814 - val_pearson_correlation_tf: 0.6095 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6541 - categorical_accuracy: 0.2904 - spearman_correlation_tf: 0.6845 - pearson_correlation_tf: 0.6102\n",
      "Epoch 21: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 118ms/step - loss: 0.6541 - categorical_accuracy: 0.2904 - spearman_correlation_tf: 0.6845 - pearson_correlation_tf: 0.6102 - val_loss: 0.6399 - val_categorical_accuracy: 0.3229 - val_spearman_correlation_tf: 0.6942 - val_pearson_correlation_tf: 0.6346 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.6162 - categorical_accuracy: 0.3175 - spearman_correlation_tf: 0.6920 - pearson_correlation_tf: 0.6361\n",
      "Epoch 22: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 120ms/step - loss: 0.6162 - categorical_accuracy: 0.3175 - spearman_correlation_tf: 0.6920 - pearson_correlation_tf: 0.6361 - val_loss: 0.6063 - val_categorical_accuracy: 0.2812 - val_spearman_correlation_tf: 0.6995 - val_pearson_correlation_tf: 0.6414 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5841 - categorical_accuracy: 0.3107 - spearman_correlation_tf: 0.6881 - pearson_correlation_tf: 0.6372\n",
      "Epoch 23: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 117ms/step - loss: 0.5841 - categorical_accuracy: 0.3107 - spearman_correlation_tf: 0.6881 - pearson_correlation_tf: 0.6372 - val_loss: 0.5697 - val_categorical_accuracy: 0.3646 - val_spearman_correlation_tf: 0.7042 - val_pearson_correlation_tf: 0.6723 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5514 - categorical_accuracy: 0.3198 - spearman_correlation_tf: 0.7053 - pearson_correlation_tf: 0.6585\n",
      "Epoch 24: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 119ms/step - loss: 0.5514 - categorical_accuracy: 0.3198 - spearman_correlation_tf: 0.7053 - pearson_correlation_tf: 0.6585 - val_loss: 0.5421 - val_categorical_accuracy: 0.3542 - val_spearman_correlation_tf: 0.6991 - val_pearson_correlation_tf: 0.6645 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.5223 - categorical_accuracy: 0.3299 - spearman_correlation_tf: 0.7018 - pearson_correlation_tf: 0.6613\n",
      "Epoch 25: val_spearman_correlation_tf did not improve from 0.70467\n",
      "28/28 [==============================] - 3s 119ms/step - loss: 0.5223 - categorical_accuracy: 0.3299 - spearman_correlation_tf: 0.7018 - pearson_correlation_tf: 0.6613 - val_loss: 0.5158 - val_categorical_accuracy: 0.3438 - val_spearman_correlation_tf: 0.7032 - val_pearson_correlation_tf: 0.6558 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4955 - categorical_accuracy: 0.3288 - spearman_correlation_tf: 0.7013 - pearson_correlation_tf: 0.6666\n",
      "Epoch 26: val_spearman_correlation_tf improved from 0.70467 to 0.70644, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 124ms/step - loss: 0.4955 - categorical_accuracy: 0.3288 - spearman_correlation_tf: 0.7013 - pearson_correlation_tf: 0.6666 - val_loss: 0.4878 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.7064 - val_pearson_correlation_tf: 0.6718 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4710 - categorical_accuracy: 0.3232 - spearman_correlation_tf: 0.7090 - pearson_correlation_tf: 0.6585\n",
      "Epoch 27: val_spearman_correlation_tf improved from 0.70644 to 0.71035, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 125ms/step - loss: 0.4710 - categorical_accuracy: 0.3232 - spearman_correlation_tf: 0.7090 - pearson_correlation_tf: 0.6585 - val_loss: 0.4614 - val_categorical_accuracy: 0.3021 - val_spearman_correlation_tf: 0.7104 - val_pearson_correlation_tf: 0.6821 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4432 - categorical_accuracy: 0.3232 - spearman_correlation_tf: 0.7119 - pearson_correlation_tf: 0.6799\n",
      "Epoch 28: val_spearman_correlation_tf improved from 0.71035 to 0.71465, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 120ms/step - loss: 0.4432 - categorical_accuracy: 0.3232 - spearman_correlation_tf: 0.7119 - pearson_correlation_tf: 0.6799 - val_loss: 0.4372 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.7146 - val_pearson_correlation_tf: 0.6869 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.4213 - categorical_accuracy: 0.3186 - spearman_correlation_tf: 0.7177 - pearson_correlation_tf: 0.6737\n",
      "Epoch 29: val_spearman_correlation_tf improved from 0.71465 to 0.71907, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 122ms/step - loss: 0.4213 - categorical_accuracy: 0.3186 - spearman_correlation_tf: 0.7177 - pearson_correlation_tf: 0.6737 - val_loss: 0.4145 - val_categorical_accuracy: 0.3438 - val_spearman_correlation_tf: 0.7191 - val_pearson_correlation_tf: 0.6860 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3997 - categorical_accuracy: 0.3650 - spearman_correlation_tf: 0.7160 - pearson_correlation_tf: 0.6812\n",
      "Epoch 30: val_spearman_correlation_tf improved from 0.71907 to 0.72260, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 0.3997 - categorical_accuracy: 0.3650 - spearman_correlation_tf: 0.7160 - pearson_correlation_tf: 0.6812 - val_loss: 0.3933 - val_categorical_accuracy: 0.3333 - val_spearman_correlation_tf: 0.7226 - val_pearson_correlation_tf: 0.6980 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3789 - categorical_accuracy: 0.3390 - spearman_correlation_tf: 0.7295 - pearson_correlation_tf: 0.6884\n",
      "Epoch 31: val_spearman_correlation_tf improved from 0.72260 to 0.72513, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 4s 127ms/step - loss: 0.3789 - categorical_accuracy: 0.3390 - spearman_correlation_tf: 0.7295 - pearson_correlation_tf: 0.6884 - val_loss: 0.3727 - val_categorical_accuracy: 0.3646 - val_spearman_correlation_tf: 0.7251 - val_pearson_correlation_tf: 0.7107 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3607 - categorical_accuracy: 0.3593 - spearman_correlation_tf: 0.7122 - pearson_correlation_tf: 0.6893\n",
      "Epoch 32: val_spearman_correlation_tf did not improve from 0.72513\n",
      "28/28 [==============================] - 3s 119ms/step - loss: 0.3607 - categorical_accuracy: 0.3593 - spearman_correlation_tf: 0.7122 - pearson_correlation_tf: 0.6893 - val_loss: 0.3580 - val_categorical_accuracy: 0.3750 - val_spearman_correlation_tf: 0.7163 - val_pearson_correlation_tf: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3416 - categorical_accuracy: 0.3853 - spearman_correlation_tf: 0.7324 - pearson_correlation_tf: 0.6960\n",
      "Epoch 33: val_spearman_correlation_tf did not improve from 0.72513\n",
      "28/28 [==============================] - 4s 127ms/step - loss: 0.3416 - categorical_accuracy: 0.3853 - spearman_correlation_tf: 0.7324 - pearson_correlation_tf: 0.6960 - val_loss: 0.3388 - val_categorical_accuracy: 0.3750 - val_spearman_correlation_tf: 0.7218 - val_pearson_correlation_tf: 0.7007 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3264 - categorical_accuracy: 0.3503 - spearman_correlation_tf: 0.7209 - pearson_correlation_tf: 0.6976\n",
      "Epoch 34: val_spearman_correlation_tf improved from 0.72513 to 0.72942, saving model to weights\\mobilenet_weights.h5\n",
      "28/28 [==============================] - 3s 126ms/step - loss: 0.3264 - categorical_accuracy: 0.3503 - spearman_correlation_tf: 0.7209 - pearson_correlation_tf: 0.6976 - val_loss: 0.3218 - val_categorical_accuracy: 0.3438 - val_spearman_correlation_tf: 0.7294 - val_pearson_correlation_tf: 0.7085 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.3098 - categorical_accuracy: 0.3446 - spearman_correlation_tf: 0.7311 - pearson_correlation_tf: 0.7033\n",
      "Epoch 35: val_spearman_correlation_tf did not improve from 0.72942\n",
      "28/28 [==============================] - 3s 121ms/step - loss: 0.3098 - categorical_accuracy: 0.3446 - spearman_correlation_tf: 0.7311 - pearson_correlation_tf: 0.7033 - val_loss: 0.3128 - val_categorical_accuracy: 0.3854 - val_spearman_correlation_tf: 0.7076 - val_pearson_correlation_tf: 0.6834 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.2939 - categorical_accuracy: 0.3571 - spearman_correlation_tf: 0.7300 - pearson_correlation_tf: 0.7086\n",
      "Epoch 36: val_spearman_correlation_tf did not improve from 0.72942\n",
      "28/28 [==============================] - 3s 120ms/step - loss: 0.2939 - categorical_accuracy: 0.3571 - spearman_correlation_tf: 0.7300 - pearson_correlation_tf: 0.7086 - val_loss: 0.2992 - val_categorical_accuracy: 0.3958 - val_spearman_correlation_tf: 0.7170 - val_pearson_correlation_tf: 0.6800 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "18/28 [==================>...........] - ETA: 1s - loss: 0.2830 - categorical_accuracy: 0.3681 - spearman_correlation_tf: 0.7384 - pearson_correlation_tf: 0.7092"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 279\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 260\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m917.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m101.\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_model_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\install\\envs\\imquality\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer, MultiHeadAttention, LayerNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from utils.data_loader import train_generator, val_generator\n",
    "\n",
    "\n",
    "# Custom TensorBoard callback for batch-level logging\n",
    "class TensorBoardBatch(tf.keras.callbacks.TensorBoard):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(TensorBoardBatch, self).__init__(*args, **kwargs)\n",
    "        self.writer = None\n",
    "        self.step = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.step += 1\n",
    "        \n",
    "        if self.writer is None:\n",
    "            self.writer = tf.summary.create_file_writer(self.log_dir)\n",
    "\n",
    "        with self.writer.as_default():\n",
    "            for name, value in logs.items():\n",
    "                if name in ['batch', 'size']:\n",
    "                    continue\n",
    "                tf.summary.scalar(f'batch_{name}', value, step=self.step)\n",
    "\n",
    "\n",
    "# Enhanced Transformer block definition\n",
    "class EnhancedTransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(EnhancedTransformerBlock, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Initial projection to match embed_dim\n",
    "        self.projection = Dense(embed_dim)\n",
    "        \n",
    "        # Multi-head attention\n",
    "        self.att = MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=embed_dim // num_heads,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Feedforward network\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation='gelu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        \n",
    "        # Layer normalizations\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Dropouts\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # Project input to embedding dimension\n",
    "        x = self.projection(inputs)\n",
    "        \n",
    "        # Reshape for attention if needed\n",
    "        if len(x.shape) == 2:\n",
    "            x = tf.expand_dims(x, axis=1)\n",
    "        \n",
    "        # Self-attention\n",
    "        attention_output = self.att(x, x)\n",
    "        attention_output = self.dropout1(attention_output, training=training)\n",
    "        out1 = self.layernorm1(x + attention_output)\n",
    "        \n",
    "        # Feedforward\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        # Remove sequence dimension if present\n",
    "        if len(out2.shape) == 3:\n",
    "            out2 = tf.squeeze(out2, axis=1)\n",
    "            \n",
    "        return out2\n",
    "\n",
    "\n",
    "# Monitor for NaN values in the loss\n",
    "class NaNMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        if 'loss' in logs and (np.isnan(logs['loss']) or np.isinf(logs['loss'])):\n",
    "            print('NaN/Inf Loss detected, terminating training...')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "# Custom loss function to calculate Earth Mover's Distance\n",
    "def improved_earth_mover_loss(y_true, y_pred):\n",
    "    epsilon = K.epsilon()\n",
    "    \n",
    "    # Ensure proper normalization\n",
    "    y_true = K.clip(y_true, epsilon, 1.0)\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0)\n",
    "    \n",
    "    # Calculate cumulative distributions\n",
    "    cdf_true = K.cumsum(y_true, axis=-1)\n",
    "    cdf_pred = K.cumsum(y_pred, axis=-1)\n",
    "    \n",
    "    # Calculate EMD\n",
    "    emd = K.mean(K.abs(cdf_true - cdf_pred), axis=-1)\n",
    "    return K.mean(emd)\n",
    "\n",
    "\n",
    "# Custom metric for Spearman Correlation\n",
    "def spearman_correlation_tf(y_true, y_pred):\n",
    "    y_true_rank = tf.argsort(tf.argsort(y_true, axis=-1), axis=-1)\n",
    "    y_pred_rank = tf.argsort(tf.argsort(y_pred, axis=-1), axis=-1)\n",
    "\n",
    "    y_true_rank = tf.cast(y_true_rank, dtype=tf.float32)\n",
    "    y_pred_rank = tf.cast(y_pred_rank, dtype=tf.float32)\n",
    "\n",
    "    mean_y_true = tf.reduce_mean(y_true_rank, axis=-1, keepdims=True)\n",
    "    mean_y_pred = tf.reduce_mean(y_pred_rank, axis=-1, keepdims=True)\n",
    "\n",
    "    cov = tf.reduce_mean((y_true_rank - mean_y_true) * (y_pred_rank - mean_y_pred), axis=-1)\n",
    "    std_y_true = tf.sqrt(tf.reduce_mean(tf.square(y_true_rank - mean_y_true), axis=-1))\n",
    "    std_y_pred = tf.sqrt(tf.reduce_mean(tf.square(y_pred_rank - mean_y_pred), axis=-1))\n",
    "\n",
    "    spearman_corr = cov / (std_y_true * std_y_pred + K.epsilon())\n",
    "    return tf.reduce_mean(spearman_corr)\n",
    "\n",
    "\n",
    "def pearson_correlation_tf(y_true, y_pred):\n",
    "    # Ensure proper shapes\n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    # Calculate the mean of y_true and y_pred along the class dimension (axis=-1)\n",
    "    mean_y_true = tf.reduce_mean(y_true, axis=-1, keepdims=True)\n",
    "    mean_y_pred = tf.reduce_mean(y_pred, axis=-1, keepdims=True)\n",
    "\n",
    "    # Compute covariance\n",
    "    covariance = tf.reduce_mean((y_true - mean_y_true) * (y_pred - mean_y_pred), axis=-1)\n",
    "\n",
    "    # Compute the standard deviations of y_true and y_pred\n",
    "    std_y_true = tf.sqrt(tf.reduce_mean(tf.square(y_true - mean_y_true), axis=-1))\n",
    "    std_y_pred = tf.sqrt(tf.reduce_mean(tf.square(y_pred - mean_y_pred), axis=-1))\n",
    "\n",
    "    # Compute Pearson correlation\n",
    "    pearson_corr = covariance / (std_y_true * std_y_pred + tf.keras.backend.epsilon())\n",
    "\n",
    "    return tf.reduce_mean(pearson_corr)\n",
    "\n",
    "\n",
    "# Model creation function with MobileNet base and transformer block\n",
    "def create_model(image_size=224, num_classes=10):  # Updated to match your output dimension\n",
    "    # Base model\n",
    "    base_model = MobileNet(\n",
    "        input_shape=(image_size, image_size, 3),\n",
    "        alpha=1.0,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers:\n",
    "        if 'block_14' in layer.name or 'block_13' in layer.name:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Build model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # This will give us (batch_size, 1024)\n",
    "    \n",
    "    # First transformer block\n",
    "    x = EnhancedTransformerBlock(\n",
    "        embed_dim=256,  # Reduced dimension\n",
    "        num_heads=4,    # Reduced heads\n",
    "        ff_dim=512,\n",
    "        dropout_rate=0.1\n",
    "    )(x)\n",
    "    \n",
    "    # Additional dense layers\n",
    "    x = Dense(128, activation='gelu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # Final prediction layer\n",
    "    predictions = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Main function to train the model\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    image_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 300\n",
    "    num_classes = 10  # Make sure this matches your data\n",
    "    initial_lr = 1e-4\n",
    "\n",
    "    # Create and compile model\n",
    "    model = create_model(image_size, num_classes)\n",
    "    optimizer = Adam(\n",
    "        learning_rate=initial_lr,\n",
    "        clipnorm=1.0,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-8\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=improved_earth_mover_loss,\n",
    "        metrics=['categorical_accuracy', spearman_correlation_tf, pearson_correlation_tf]\n",
    "    )\n",
    "    \n",
    "    # Print model summary to verify shapes\n",
    "    model.summary()\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            'weights/mobilenet_weights.h5',\n",
    "            monitor='val_spearman_correlation_tf',\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        TensorBoardBatch(log_dir=os.path.join('./logs', datetime.now().strftime(\"%Y%m%d-%H%M%S\"))),\n",
    "        NaNMonitor(),\n",
    "        #EarlyStopping(\n",
    "           # monitor='val_spearman_correlation_tf',\n",
    "          #  patience=50,\n",
    "           # verbose=1,\n",
    "           # restore_best_weights=True\n",
    "        #),\n",
    "        \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=150,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Training\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            train_generator(batchsize=batch_size),\n",
    "            steps_per_epoch=(917. // batch_size),\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=val_generator(batchsize=batch_size),\n",
    "            validation_steps=(101. // batch_size),\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "        model.save_weights('final_model_weights.h5')\n",
    "        print(\"Training completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba72b328-6545-499a-8509-36eac67295f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c94c8-3e1d-49b2-8b1d-bc1529f04e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
